{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alpha_vantage in /usr/local/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/anaconda3/lib/python3.8/site-packages (from alpha_vantage) (3.7.4.post0)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from alpha_vantage) (2.24.0)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp->alpha_vantage) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp->alpha_vantage) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp->alpha_vantage) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp->alpha_vantage) (20.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp->alpha_vantage) (3.7.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp->alpha_vantage) (1.6.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->alpha_vantage) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->alpha_vantage) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->alpha_vantage) (2.10)\n",
      "Collecting google-auth\n",
      "  Downloading google_auth-1.28.0-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 24.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth) (50.3.0.post20201006)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from google-auth) (1.15.0)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyasn1, pyasn1-modules, cachetools, rsa, google-auth\n",
      "Successfully installed cachetools-4.2.1 google-auth-1.28.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install alpha_vantage\n",
    "! pip install google-auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import json\n",
    "\n",
    "\n",
    "def save_dataset(symbol):\n",
    "    #credentials = json.load(open('creds.json', 'r'))\n",
    "    api_key = 'P33J9T7IVI663Y0A'\n",
    "\n",
    "    ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol, outputsize='full')\n",
    "\n",
    "    data.to_csv(f'./{symbol}_daily.csv')\n",
    "    \n",
    "save_dataset(\"AAPL\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "history_points = 50\n",
    "\n",
    "def csv_to_dataset(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data = data.drop('date', axis=1)\n",
    "    data = data.drop(0, axis=0)\n",
    "    data_normaliser = preprocessing.MinMaxScaler()\n",
    "    data_normalised = data_normaliser.fit_transform(data)\n",
    "    # using the last {history_points} open high low close volume data points, predict the next open value\n",
    "    ohlcv_histories_normalised = np.array([data_normalised[i  : i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    next_day_open_values_normalised = np.array([data_normalised[:,0][i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)\n",
    "\n",
    "    next_day_open_values = np.array([data.iloc[:,0][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "    #next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "    y_normaliser = preprocessing.MinMaxScaler()\n",
    "    y_normaliser.fit(np.expand_dims( next_day_open_values, -1))\n",
    "    \n",
    "    assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0]\n",
    "    return ohlcv_histories_normalised, next_day_open_values_normalised, next_day_open_values, y_normaliser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohlcv_histories, next_day_open_values, unscaled_y, y_normaliser = csv_to_dataset('AAPL_daily.csv')\n",
    "\n",
    "\n",
    "test_split = 0.9 # the percent of data to be used for testing\n",
    "n = int(ohlcv_histories.shape[0] * test_split)\n",
    "\n",
    "#splitting the dataset up into train and test sets\n",
    "\n",
    "ohlcv_train = ohlcv_histories[:n]\n",
    "y_train = next_day_open_values[:n]\n",
    "\n",
    "ohlcv_test = ohlcv_histories[n:]\n",
    "y_test = next_day_open_values[n:]\n",
    "\n",
    "unscaled_y_test = unscaled_y[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /usr/local/anaconda3/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from pydot) (2.4.7)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement graphiz (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for graphiz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "tf.random.set_seed(4)\n",
    "#set_random_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "lstm_input = Input(shape=(history_points, 5), name='lstm_input')\n",
    "x = LSTM(50, name='lstm_0')(lstm_input)\n",
    "x = Dropout(0.2, name='lstm_dropout_0')(x)\n",
    "x = Dense(64, name='dense_0')(x)\n",
    "x = Activation('sigmoid', name='sigmoid_0')(x)\n",
    "x = Dense(1, name='dense_1')(x)\n",
    "output = Activation('linear', name='linear_output')(x)\n",
    "model = Model(inputs=lstm_input, outputs=output)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0005)\n",
    "\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
